# RemindAR - AI-Powered AR Memory Assistant

An emotional, demo-ready AR memory assistant that helps people with memory loss recognize faces and remember important context about the people in their lives.

![RemindAR Demo](https://via.placeholder.com/800x400/0a0a0f/ffffff?text=RemindAR+-+AR+Memory+Assistant)

## ğŸ¯ What It Does

RemindAR uses your webcam to simulate AR glasses:
1. **Detects faces** in real-time using MediaPipe (in-browser)
2. **Recognizes identities** using InsightFace deep learning embeddings
3. **Displays floating AR labels** with name, relationship, and context
4. **Smooth, calm animations** designed for accessibility

## âœ¨ Features

- ğŸ¥ **Real-time face detection** - MediaPipe running entirely in-browser
- ğŸ§  **AI-powered recognition** - InsightFace generates face embeddings for matching
- ğŸ­ **Smooth AR overlays** - Three.js renders floating text labels
- ğŸ’¾ **Persistent memory** - SQLite stores identities and context
- ğŸŒ **WebSocket communication** - Low-latency real-time updates
- â™¿ **Accessibility-first** - Large fonts, soft glow, minimal motion

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.9+** (for backend)
- **Node.js 18+** (for frontend)
- **Webcam** with browser access permissions

### 1. Clone the Repository

```bash
cd /path/to/RemindAR
```

### 2. Start the Backend

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Start the server
python main.py
```

The backend will:
- Initialize the SQLite database
- Download InsightFace model (~300MB on first run)
- Start WebSocket server on `ws://localhost:8000/ws`

### 3. Start the Frontend

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

Open `http://localhost:5173` in your browser.

### 4. Allow Camera Access

When prompted, allow camera access to see the AR overlay in action.

---

## ğŸ“‹ Demo Flow

1. **Start both servers** (backend and frontend)
2. **Open the frontend** in your browser
3. **Allow camera access** when prompted
4. **Show a face** - You'll see "Analyzing..." then either:
   - **Known person**: Name, relation, and context appear
   - **Unknown person**: "New Person" label appears

### Pre-loaded Demo Identities

The database comes seeded with 4 demo identities:
- **Sarah** - Daughter
- **Dr. Patel** - Doctor
- **Mike** - Neighbor
- **Emma** - Granddaughter

> **Note**: These identities need face photos to be registered before recognition works. See [Registering Faces](#registering-faces) below.

---

## ğŸ–¼ï¸ Registering Faces

To register a face for a known identity:

### Option 1: REST API

```bash
# Register a face for an existing person
curl -X POST "http://localhost:8000/register-face/demo_001" \
  -H "Content-Type: application/json" \
  -d '{"track_id": "sarah_1", "image_base64": "<base64-encoded-face-image>"}'
```

### Option 2: Add New Person

```bash
# Create a new person
curl -X POST "http://localhost:8000/people" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "John",
    "relation": "Son",
    "last_met": "Today",
    "context": "Brought groceries"
  }'
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Camera  â”‚â†’ â”‚  MediaPipe   â”‚â†’ â”‚  Face Tracking +      â”‚  â”‚
â”‚  â”‚  (WebRTC)â”‚  â”‚  Detection   â”‚  â”‚  Bounding Box Smooth  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                            â”‚                â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚                                    â”‚  WebSocket    â”‚        â”‚
â”‚                                    â”‚  (face crops) â”‚        â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                â”‚
â”‚  â”‚  Three.js AR Overlay         â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚  â”‚  (floating text labels)      â”‚    (identity + context)   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                     WebSocket Connection
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BACKEND                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI â”‚â†’ â”‚  InsightFace â”‚â†’ â”‚  Embedding Matching   â”‚  â”‚
â”‚  â”‚  Server  â”‚  â”‚  (buffalo_l) â”‚  â”‚  (cosine similarity)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                            â”‚                â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚                                    â”‚    SQLite     â”‚        â”‚
â”‚                                    â”‚  (identities) â”‚        â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
RemindAR/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI server + WebSocket
â”‚   â”œâ”€â”€ face_recognition.py  # InsightFace integration
â”‚   â”œâ”€â”€ database.py          # SQLite operations
â”‚   â”œâ”€â”€ models.py            # Pydantic schemas
â”‚   â””â”€â”€ requirements.txt     # Python dependencies
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx                  # Main application
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Camera.tsx           # Webcam capture
â”‚   â”‚   â”‚   â”œâ”€â”€ AROverlay.tsx        # Three.js overlay
â”‚   â”‚   â”‚   â”œâ”€â”€ PersonLabel.tsx      # Individual labels
â”‚   â”‚   â”‚   â””â”€â”€ StatusIndicator.tsx  # Connection status
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useWebSocket.ts      # WebSocket connection
â”‚   â”‚   â”‚   â””â”€â”€ useFaceDetection.ts  # MediaPipe detection
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ faceUtils.ts         # Helper functions
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts             # TypeScript types
â”‚   â”‚   â””â”€â”€ styles/
â”‚   â”‚       â””â”€â”€ index.css            # Global styles
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â””â”€â”€ README.md
```

---

## ğŸ”§ Configuration

### Backend Environment

| Variable | Default | Description |
|----------|---------|-------------|
| `HOST` | `0.0.0.0` | Server host |
| `PORT` | `8000` | Server port |

### Frontend Environment

Create `.env` in `frontend/`:

```env
VITE_WS_URL=ws://localhost:8000/ws
```

---

## ğŸ¨ UI Design Philosophy

- **Text-only overlays** - No cards, boxes, or distracting UI
- **Maximum 3 lines** - Name, relation, and context
- **Soft white glow** - Readable on any background
- **Gentle animations** - Fade in/out, subtle float
- **Accessibility-first** - Large fonts, reduced motion support

---

## ğŸ”® Future Expansion Points

The following features are stubbed for future implementation:

```typescript
// TODO: Caregiver dashboard for managing identities
// TODO: Voice-based memory capture
// TODO: Long-term conversation memory with ChromaDB
// TODO: Mobile AR (ARCore/ARKit) integration
// TODO: Speaker diarization for multi-person conversations
```

---

## ğŸ› Troubleshooting

### Camera not working
- Ensure browser has camera permissions
- Try a different browser (Chrome recommended)
- Check if another app is using the camera

### WebSocket disconnected
- Verify backend is running on port 8000
- Check browser console for errors
- Ensure no firewall blocking WebSocket

### Faces not recognized
- Register faces via the API first
- Ensure good lighting and face visibility
- Try adjusting similarity threshold in `face_recognition.py`

### Slow performance
- Close other camera-using applications
- Reduce browser tab count
- Try lowering detection resolution

---

## ğŸ“„ License

MIT License - Feel free to use for hackathons and personal projects.

---

## ğŸ™ Acknowledgments

- [MediaPipe](https://mediapipe.dev/) - In-browser face detection
- [InsightFace](https://github.com/deepinsight/insightface) - Face recognition embeddings
- [Three.js](https://threejs.org/) - 3D WebGL rendering
- [FastAPI](https://fastapi.tiangolo.com/) - Python web framework

---

Built with â¤ï¸ for people with memory loss and their caregivers.
